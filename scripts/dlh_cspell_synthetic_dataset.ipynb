{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSpell Misspelling Correction Dataset\n",
    "\n",
    "This script converts the misspelling detection / correct dataset by CSpell team ([link](https://lsg3.nlm.nih.gov/LexSysGroup/Projects/cSpell/current/web/index.html)) into our format. There are selection processes to filter some examples in CSpell dataset:\n",
    "\n",
    "- The CSpell dataset contains different types of misspellings, and we carefully choose as much as possible. Also the datset has multiple-word misspellings and misspellings with special symbols (like punctuations). We filtered out such examples and keep only single-word/alphabet only misspellings.\n",
    "- Since the CSpell is a software that detect & correct misspellings, while ours only correct misspellings, we filter out the examples that are not detected by CSpell. Please refer to `scripts/cspell_results.ipynb` for reproduction of the performance by CSpell and the masks we used to filter examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/cspell/train\n"
     ]
    }
   ],
   "source": [
    "train_url = '/TrainSet_brat.tgz'\n",
    "test_url = '/TestSet_reconciled.tgz'\n",
    "\n",
    "train_fname = os.path.basename(train_url)\n",
    "test_fname = os.path.basename(test_url)\n",
    "\n",
    "dataset_dir = '../data/cspell/'\n",
    "\n",
    "# CSpell files\n",
    "train_tar_fpath = os.path.join(dataset_dir, train_fname)\n",
    "test_tar_fpath = os.path.join(dataset_dir, test_fname)\n",
    "train_dir = \"../data/cspell/train\"\n",
    "test_dir = \"../data/cspell/test\"\n",
    "#train_dir = os.path.join(dataset_dir, os.path.splitext(train_fname)[0])\n",
    "#test_dir = os.path.join(dataset_dir, os.path.splitext(test_fname)[0])\n",
    "\n",
    "print(train_dir)\n",
    "\n",
    "# Output files\n",
    "output_train_before_fname = 'train_before.tsv'  # Not filtered by CSpell detection\n",
    "output_test_before_fname = 'test_before.tsv'\n",
    "output_train_fname = 'train.tsv'  # Filtered by CSpell detection\n",
    "output_test_fname = 'test.tsv'\n",
    "\n",
    "# Excluded by NLM\n",
    "ann_fnames_exclude = ['11199.ann']\n",
    "ann_fnames_exclude = set(ann_fnames_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download CSpell dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(train_url, train_tar_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(test_url, test_tar_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(tar_fpath, extract_path='.'):\n",
    "    print(f'Extract {tar_fpath} to {extract_path}')\n",
    "    print(tar_fpath)\n",
    "    tar = tarfile.open(tar_fpath, 'r')\n",
    "    for item in tar:\n",
    "        tar.extract(item, extract_path)\n",
    "        if item.name.find(\".tgz\") != -1 or item.name.find(\".tar\") != -1:\n",
    "            extract(item.name, \"./\" + item.name[:item.name.rfind('/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract(train_tar_fpath, dataset_dir)\n",
    "extract(test_tar_fpath, dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of the misspellings + Selection strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(line, num_tokens):\n",
    "    line = line.strip()\n",
    "    tokens = []\n",
    "    for i in range(num_tokens):\n",
    "        space_start, space_end = 0, 0\n",
    "        for j, c in enumerate(line):\n",
    "            if c.isspace() and space_start == 0:\n",
    "                space_start = j\n",
    "            if not c.isspace() and space_start != 0:\n",
    "                space_end = j\n",
    "                break\n",
    "        if space_end == 0 or space_end == 0:\n",
    "            raise ValueError(f'Can find {i}-th token: {line}')\n",
    "        \n",
    "        tokens.append(line[:space_start])\n",
    "        line = line[space_end:]\n",
    "    return tokens, line\n",
    "\n",
    "def read_ann(ann_fpath):\n",
    "    print(ann_fpath)\n",
    "    with open(ann_fpath) as fd:\n",
    "        lines = fd.readlines()\n",
    "\n",
    "    typos, corrections = [], {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('A'):  # Important annotation -> skip\n",
    "            continue\n",
    "        elif line.startswith('T'):  # Misspelling locations\n",
    "            tokens, remaining = get_tokens(line, 4)\n",
    "            typo_label, typo_type, typo_span, typo = tokens[0], tokens[1], (int(tokens[2]), int(tokens[3])), remaining\n",
    "            typos.append((typo_label, typo_type, typo_span, typo))\n",
    "        elif line.startswith('#'):  # Correction to the annotations\n",
    "            tokens, remaining = get_tokens(line, 3)\n",
    "            cor_label, typo_label, correction = tokens[0], tokens[2], remaining\n",
    "            corrections[typo_label] = (cor_label, correction)\n",
    "        else:\n",
    "            raise ValueError(f'Wrong header: {line}')\n",
    "    \n",
    "    typos.sort(key=lambda x: (x[2][0], -x[2][1]))  # Note: There can be overlapped annotations,\n",
    "                                                   #       Sort them so that the former will contain the latter\n",
    "    results = []\n",
    "    for typo_label, typo_type, typo_span, typo in typos:\n",
    "        if typo_label in corrections:\n",
    "            results.append((typo_label, typo_type, typo_span, typo, corrections[typo_label][1]))\n",
    "        else:\n",
    "            results.append((typo_label, typo_type, typo_span, typo, None))\n",
    "#             print(f'{ann_fname} - {typo_label}')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ann_stat(dataset_root, print_overlap=False, type_show=None):\n",
    "    print(f'Dataset dir: {dataset_root}')\n",
    "    ann_fnames = [fname for fname in os.listdir(dataset_root) if fname.endswith('.ann')]\n",
    "    ann_cor_counter = collections.defaultdict(lambda: [0, 0, 0, 0])\n",
    "    total_ann_lines = 0\n",
    "    total_anns = 0\n",
    "    cnt_empty_ann_files = 0\n",
    "    cnt_empty_anns = 0\n",
    "\n",
    "    if type_show:\n",
    "        print(f'\\n[Annotations of ({type_show})]')\n",
    "        print(f'{\"Location(span)\":60s} Typo            Correction      Overlapped')\n",
    "        \n",
    "    for ann_fname in ann_fnames:\n",
    "        if ann_fname in ann_fnames_exclude:\n",
    "            continue\n",
    "    \n",
    "        # Get typo annotations\n",
    "        ann_fpath = os.path.join(dataset_root, ann_fname)\n",
    "        ann_fcontent = [l.strip() for l in open(ann_fpath).readlines() if l.strip()]\n",
    "        anns = read_ann(ann_fpath)\n",
    "        total_ann_lines += len(ann_fcontent)\n",
    "        total_anns += len(anns)\n",
    "        cnt_empty_ann_files += int(len(ann_fcontent) == 0)\n",
    "        cnt_empty_anns += int(len(anns) == 0)\n",
    "\n",
    "        # Count types of typos, according the presence of correction\n",
    "        for ann in anns:\n",
    "            typo_label, typo_type, (start, end), typo, correction = ann\n",
    "            ann_cor_counter[typo_type][0] += 1\n",
    "            ann_cor_counter[typo_type][int(correction is None) + 1] += 1\n",
    "\n",
    "        # Overlapped annotations\n",
    "        temp = set()\n",
    "        for i, ann1 in enumerate(anns):\n",
    "            for j, ann2 in enumerate(anns):\n",
    "                if i >= j: continue\n",
    "                start1, end1 = ann1[2]\n",
    "                start2, end2 = ann2[2]\n",
    "                if not (end1 <= start2 or end2 <= start1):\n",
    "                    temp.add(i)\n",
    "                    temp.add(j)\n",
    "                    if print_overlap and not (ann1[1] == 'RealWord' or ann2[1] == 'RealWord'):\n",
    "                        print(f'\\t{ann1}')\n",
    "                        print(f'\\t{ann2}')\n",
    "        for i in temp:\n",
    "            ann_cor_counter[anns[i][1]][3] += 1\n",
    "        \n",
    "        # Show a specific type of typo\n",
    "        if type_show:\n",
    "            for i, ann in enumerate(anns):\n",
    "                if ann[1] == type_show:\n",
    "                    print(f'{ann_fpath + str(ann[2]):60s} {ann[3]:15s} {ann[4] if ann[4] else \"[None]\":15s} {i in temp}')\n",
    "\n",
    "    # Output stats\n",
    "    print(f'\\nTotal {len(set(ann_fnames) - ann_fnames_exclude)} ann files')\n",
    "    print(f'  {cnt_empty_ann_files} empty files, {cnt_empty_anns} empty anns')\n",
    "    print(f'Total {total_anns} anns from {total_ann_lines} lines')\n",
    "\n",
    "    typo_types_temp = sorted(ann_cor_counter.keys())\n",
    "    print('\\nTypo Type        Total  Cor O  Cor X  Dupli')\n",
    "    for typo_type in typo_types_temp:\n",
    "        print(f'{typo_type:15s}' + ''.join([f'{n:7d}' for n in ann_cor_counter[typo_type]]))\n",
    "    print('(Total)        ' + ''.join([f'{sum(l):7d}' for l in zip(*list(ann_cor_counter.values()))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSpell train set\n",
    "\n",
    "### Annotation types\n",
    "\n",
    "Typo -> Use only 1 word/1 word annotations\n",
    "- Misspelling: 1+ word -> 1+ word\n",
    "- Grammatical: 1+ word -> 0+ word (0: to delete)\n",
    "- Punctuation: \n",
    "\n",
    "Typo, but do not use it\n",
    "- ToSplit: 2+ words -> 1 word\n",
    "- ToMerge: 1 word -> 2+ word\n",
    "\n",
    "Extra\n",
    "- RealWord: Real word typo. 1+ word -> 1+ word\n",
    "\n",
    "### Selection strategies\n",
    "\n",
    "These types are chosen as an example\n",
    "- Misspelling with one-word (& alphabet)\n",
    "- Grammatical with one-word (& alphabet)\n",
    "- Punctuation with one-word (& alphabet) -> no alphabet-only typo!\n",
    "- RealWord with one-word (& alphabet): remove if duplicate with other annotations (ToSplit, Misspelling, Grammatical)\n",
    "\n",
    "These are not chosen\n",
    "- ToSplit, ToMerge\n",
    "\n",
    "### Correcting strategies for each annotation types\n",
    "\n",
    "- Grammatical: Apply (remove if correction is None)\n",
    "- Misspelling, ToMerge, ToSplit: Apply (ignore if correction is None)\n",
    "- Realword: Apply if not duplicate with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dir: ../data/cspell/TrainSet_brat\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/cspell/TrainSet_brat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train set distribution\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# type_show = 'RealWord'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m type_show \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mshow_ann_stat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_show\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_show\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m, in \u001b[0;36mshow_ann_stat\u001b[0;34m(dataset_root, print_overlap, type_show)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_ann_stat\u001b[39m(dataset_root, print_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, type_show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset dir: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     ann_fnames \u001b[38;5;241m=\u001b[39m [fname \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m fname\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.ann\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      4\u001b[0m     ann_cor_counter \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m     total_ann_lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/cspell/TrainSet_brat'"
     ]
    }
   ],
   "source": [
    "# Train set distribution\n",
    "# type_show = 'RealWord'\n",
    "type_show = None\n",
    "show_ann_stat(train_dir, type_show=type_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSpell test set\n",
    "\n",
    "### Annotation types\n",
    "\n",
    "Typo -> Use only 1 word/1 word annotations\n",
    "- Informal: 1+ word (informal expression) -> 1+ word (ABB:/ACR: can precede)\n",
    "- Misspelling: 1+ word -> 1+ word\n",
    "- Punctuation: 1 word -> 1 word (ends with a punctuation)\n",
    "- RealWord: Real word typo. 1+ word -> 1+ word\n",
    "\n",
    "Typo, but do not use it\n",
    "- ToMerge: 2+ words -> 1 word, mostly do not have label\n",
    "- ToSplit: 1 word -> multiple words\n",
    "- ToSplitOnPunct: Similar to \"ToSplit\", but these do not have corrections (because they are trivial)\n",
    "\n",
    "Not a typo\n",
    "- Unknown: Not valid words, but can not find corretions\n",
    "- WordExists: Not a typo -> Do not use this as a typo example\n",
    "- Garbage: No need to be corrected\n",
    "\n",
    "### Selection strategy\n",
    "\n",
    "These types are chosen as an example\n",
    "- Misspelling with one-word (& alphabet)\n",
    "- RealWord with one-word (& alphabet)\n",
    "- Informal with one-word (& alphabet)  -> **Need to check this**\n",
    "\n",
    "These are not chosen\n",
    "- Punctuation: test examples of this type only does not have a punctuation at the end\n",
    "\n",
    "\n",
    "### Correcting strategy for each annotation types\n",
    "\n",
    "- ToSplit, Misspelling, Punctuation: Apply correction\n",
    "- Informal: Apply correction, with `ABB: ` and `ACR: ` deleted (ignore if correction is None)\n",
    "- ToSplitOnPunct: find split chars (`.?,&()-*/`) and add a space after that\n",
    "- ToMerge: delete chars (space, `-`)\n",
    "- WordExists, Unknown, RealWord, Garbage: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set distribution\n",
    "show_ann_stat(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract misspelling examples\n",
    "\n",
    "We define several filtering functions to extract the dataset, and we have different selection rules between train and test set based on the analysis above.\n",
    "\n",
    "- Choose valid types of misspellings in\n",
    "    - Train set: `choose_anns_for_example_train()`\n",
    "    - Test set: `choose_anns_for_example_test()`\n",
    "- Filter out duplidates in\n",
    "    - Train set: `filter_anns_for_context_train()`\n",
    "    - Test set: `X`\n",
    "- Find out corrections for each annotation to filter examples in\n",
    "    - Train set: `get_correction_for_clean_context_train()`\n",
    "    - Test set: `get_correction_for_clean_context_test()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_anns_for_example_train(anns):\n",
    "    anns_valid = []\n",
    "    for ann in anns:\n",
    "        typo_label, typo_type, (start, end), typo, correction = ann\n",
    "        # select Misspelling, Grammatical, Punctuation, RealWord\n",
    "        if typo_type not in ['Misspelling', 'Grammatical', 'Punctuation', 'RealWord']:\n",
    "            continue\n",
    "        if len(typo.split()) != 1 or not(correction) or len(correction.split()) != 1:\n",
    "            continue\n",
    "        anns_valid.append(ann)\n",
    "    \n",
    "    # Remove duplicate 'RealWord'\n",
    "    anns_valid2 = []\n",
    "    for i, ann in enumerate(anns_valid):\n",
    "        typo_label, typo_type, (start, end), typo, correction = ann\n",
    "        flag = True\n",
    "        if typo_type == 'RealWord':\n",
    "            for ann2 in anns_valid:\n",
    "                start2, end2 = ann[2]\n",
    "                if ann != ann2 and not (start2 >= end or end2 <= start):\n",
    "                    flag = False\n",
    "        if flag:\n",
    "            anns_valid2.append(ann)\n",
    "                    \n",
    "    return anns_valid2\n",
    "\n",
    "def choose_anns_for_example_test(anns):\n",
    "    anns_valid = []\n",
    "    for ann in anns:\n",
    "        typo_label, typo_type, (start, end), typo, correction = ann\n",
    "        # select Misspelling, RealWord, Informal\n",
    "        if typo_type not in ['Misspelling', 'RealWord', 'Informal']:\n",
    "            continue\n",
    "        if len(typo.split()) != 1 or not(correction) or len(correction.split()) != 1:\n",
    "            continue\n",
    "        anns_valid.append(ann)\n",
    "    return anns_valid\n",
    "\n",
    "\n",
    "def filter_anns_for_context_train(anns_all, ann):\n",
    "    # Remove 'RealWord' annotations that duplicate with others\n",
    "    anns_valid = []\n",
    "    for ann2 in anns_all:\n",
    "        typo_label2, typo_type2, (start2, end2), typo2, correction2 = ann2\n",
    "        flag = True\n",
    "        if ann2 != ann and typo_type2 == 'RealWord':\n",
    "            for ann3 in anns_all:\n",
    "                typo_label3, typo_type3, (start3, end3), typo3, correction3 = ann3\n",
    "                if ann3 != ann2 and not (start3 >= end2 or end3 <= start2):\n",
    "                    flag = False\n",
    "                    break\n",
    "        if flag:\n",
    "            anns_valid.append(ann2)\n",
    "    return anns_valid\n",
    "\n",
    "\n",
    "def get_correction_for_clean_context_train(ann, txt_correct):\n",
    "    typo_label, typo_type, (start, end), typo, correction = ann\n",
    "    if typo_type == 'Grammatical':\n",
    "        return correction if correction else ''\n",
    "    elif typo_type in ['Misspelling', 'ToMerge', 'ToSplit']:\n",
    "        return correction if correction else typo\n",
    "    elif typo_type == 'RealWord':\n",
    "        return correction if correction else typo\n",
    "    elif typo_type == 'Punctuation':\n",
    "        return correction\n",
    "    else:\n",
    "        raise ValueError(f'Wrong annotation: {ann}')\n",
    "\n",
    "def get_correction_for_clean_context_test(ann, txt_correct):\n",
    "    typo_label, typo_type, (start, end), typo, correction = ann\n",
    "    if typo_type in ['ToSplit', 'Misspelling', 'Punctuation']:\n",
    "        return correction\n",
    "    elif typo_type == 'Informal':\n",
    "        if correction is None: return typo\n",
    "        elif correction.startswith('ABB: '): return correction[5:]\n",
    "        elif correction.startswith('ACR: '): return correction[5:]\n",
    "        else: return correction\n",
    "    elif typo_type == 'ToSplitOnPunct':\n",
    "        punct_chars = list(\".?,&()-*/\")\n",
    "        new_correction = typo\n",
    "        for i in range(len(new_correction)-1, -1, -1):\n",
    "            if new_correction[i] in punct_chars and new_correction[i+1] not in punct_chars:\n",
    "                new_correction = new_correction[:i] + ' ' + new_correction[i+1:]\n",
    "        return new_correction\n",
    "    elif typo_type == 'ToMerge':\n",
    "        return typo.replace(' ', '').replace('-', '')\n",
    "    elif typo_type in ['WordExists', 'Unknown', 'RealWord', 'Garbage']:\n",
    "        return typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_typo_examples(dataset_root,\n",
    "                      choose_ex_ann_fn,       # Choose anns to use as examples\n",
    "                      filter_context_ann_fn,  # Filter some anns for cleaning text\n",
    "                      get_correction_fn,      # Get correction according to its annotation type\n",
    "                      verbose=False):\n",
    "    # Load anns\n",
    "    ann_fnames = sorted([fname for fname in os.listdir(dataset_root) if fname.endswith('.ann')])\n",
    "    if verbose: print(f'{len(ann_fnames)} annotations')\n",
    "        \n",
    "    # Parsing each ann\n",
    "    typo_examples = []  # index, note_id, type, typo, left, right, correct\n",
    "    for ann_fname in ann_fnames:\n",
    "        if ann_fname in ann_fnames_exclude: \n",
    "            if verbose: print(f'  {ann_fname} - skip')\n",
    "            continue\n",
    "\n",
    "        # Read ann, text\n",
    "        note_id = os.path.splitext(ann_fname)[0]\n",
    "        anns = read_ann(os.path.join(dataset_root, ann_fname))\n",
    "        txt_fname = note_id + '.txt'\n",
    "        with open(os.path.join(dataset_root, txt_fname)) as fd:\n",
    "            txt = fd.read()\n",
    "\n",
    "        # Get the valid ann 1: From the filter function\n",
    "        anns_valid = choose_ex_ann_fn(anns)\n",
    "\n",
    "        # Get the valid ann 2: not overlapped to each other\n",
    "        anns_valid, anns_temp = [], anns_valid\n",
    "        last_end = 0\n",
    "        for ann in anns_temp:\n",
    "            typo_label, typo_type, (start, end), typo, correction = ann\n",
    "            if start < last_end: continue\n",
    "            anns_valid.append(ann)\n",
    "            last_start = start\n",
    "\n",
    "        # Get dataset examples\n",
    "        # For each typo example, we correct other typos to make the surrounding context clean\n",
    "        if verbose: print(f'  {ann_fname} - {len(anns_valid)} valid annos')\n",
    "        for ann in anns_valid:\n",
    "            # Get anns for cleaning context\n",
    "            anns_context = filter_context_ann_fn(anns, ann) if filter_context_ann_fn else anns\n",
    "            \n",
    "            typo_label, typo_type, (start, end), typo, correction = ann\n",
    "            txt_correct, last_start = txt, len(txt) + 1\n",
    "            for ann2 in anns_context[::-1]:\n",
    "                typo_label2, typo_type2, (start2, end2), typo2, correction2 = ann2\n",
    "                if end2 >= last_start: continue\n",
    "                if ann == ann2:\n",
    "                    right = txt_correct[end2:]\n",
    "                    txt_correct = txt_correct[:start2]\n",
    "                else:\n",
    "#                     print(ann2)\n",
    "#                     print(txt_correct[:start2])\n",
    "#                     print(get_correction_fn(ann2, txt_correct))\n",
    "#                     print(txt_correct[end2:])\n",
    "                    txt_correct = txt_correct[:start2] + get_correction_fn(ann2, txt_correct) + txt_correct[end2:]\n",
    "                last_start = start2\n",
    "            left = txt_correct\n",
    "            typo_examples.append((len(typo_examples), note_id, typo_type, typo, left, right, correction))\n",
    "    return typo_examples    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_train = get_typo_examples(train_dir,\n",
    "                                   choose_anns_for_example_train,\n",
    "                                   filter_anns_for_context_train,\n",
    "                                   get_correction_for_clean_context_train,\n",
    "                                   True)\n",
    "print(f'{train_dir}: {len(examples_train)} examples')\n",
    "\n",
    "type_counter = collections.Counter([e[2] for e in examples_train])\n",
    "for k, v in type_counter.items():\n",
    "    print(f'{k:15s}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_all = []   # For CIM\n",
    "examples_train_cspell_all = []  # For CSpell\n",
    "\n",
    "for example in examples_train:\n",
    "    ex_id, note_id, typo_type, typo, left, right, correction = example\n",
    "    \n",
    "    # Process for our model\n",
    "    note_id = int(note_id.split('-')[-1])\n",
    "    typo, correction = typo.lower(), correction.lower()\n",
    "    left, right = left.strip().replace('\\t', ' ').replace('\\n', ' '), right.strip().replace('\\n', ' ')\n",
    "    \n",
    "    alpha_check = all([c.isalpha() for c in typo]) and all([c.isalpha() for c in correction])\n",
    "    if alpha_check:\n",
    "        ex_id = len(dataset_train_all)\n",
    "        ex = (ex_id, note_id, typo, left, right, correction)\n",
    "        dataset_train_all.append(ex)\n",
    "        ex2 = (ex_id,) + example[1:]\n",
    "        examples_train_cspell_all.append(ex2)\n",
    "    \n",
    "print(f'Test set (before CSpell filtering): {len(dataset_train_all)} examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_test = get_typo_examples(test_dir,\n",
    "                                  choose_anns_for_example_test,\n",
    "                                  None,\n",
    "                                  get_correction_for_clean_context_test,\n",
    "                                  True)\n",
    "print(f'{test_dir}: {len(examples_test)} examples')\n",
    "\n",
    "type_counter = collections.Counter([e[2] for e in examples_test])\n",
    "for k, v in type_counter.items():\n",
    "    print(f'{k:15s}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_all = []   # For CIM\n",
    "examples_test_cspell_all = []  # For CSpell\n",
    "\n",
    "for example in examples_test:\n",
    "    ex_id, note_id, typo_type, typo, left, right, correction = example\n",
    "    \n",
    "    # Process for our model\n",
    "    note_id = int(note_id.split('-')[-1])\n",
    "    typo, correction = typo.lower(), correction.lower()\n",
    "    left, right = left.strip().replace('\\t', ' ').replace('\\n', ' '), right.strip().replace('\\n', ' ')\n",
    "    \n",
    "    # Select only single-word alphabet-only examples\n",
    "    alpha_check = all([c.isalpha() for c in typo]) and all([c.isalpha() for c in correction])\n",
    "    if alpha_check:\n",
    "        ex_id = len(dataset_test_all)\n",
    "        ex = (ex_id, note_id, typo, left, right, correction)\n",
    "        dataset_test_all.append(ex)\n",
    "        ex2 = (ex_id,) + example[1:]\n",
    "        examples_test_cspell_all.append(ex2)\n",
    "    \n",
    "print(f'Test set (before CSpell filtering): {len(dataset_test_all)} examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write dataset before CSpell filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for our CIM model\n",
    "def write_dataset(examples, output_fpath):\n",
    "    # examples: list of (ex_id, note_id, typo, left, right, correction)\n",
    "    with open(output_fpath, 'w') as fd:\n",
    "        writer = csv.writer(fd, delimiter='\\t')\n",
    "        writer.writerow(['index', 'note_id', 'word', 'left', 'right', 'correct'])  \n",
    "        for ex in examples:\n",
    "            writer.writerow(ex)\n",
    "            \n",
    "def read_dataset(dataset_fpath):\n",
    "    with open(dataset_fpath) as fd:\n",
    "        reader = csv.reader(fd)\n",
    "        dataset = list(reader)[1:]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train_fpath = os.path.join(dataset_dir, output_train_before_fname)\n",
    "print(f'Write {len(dataset_train_all)} examples to {output_train_fpath}')\n",
    "write_dataset(dataset_train_all, output_train_fpath)\n",
    "\n",
    "output_test_fpath = os.path.join(dataset_dir, output_test_before_fname)\n",
    "print(f'Write {len(dataset_test_all)} examples to {output_test_fpath}')\n",
    "write_dataset(dataset_test_all, output_test_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write examples for CSpell\n",
    "\n",
    "We write the datasets generated so far to files so that we can run CSpell on them.\n",
    "After we run CSpell, we choose only examples that are detected as misspellings by CSpell (the filtering masks are already given below for easier reproduction).\n",
    "To get the detailed output of CSpell, please run with `-t` and `-d` option enabled:\n",
    "```\n",
    "$ cspell -t -i:(input_file) -o:(output_file) -d > (debug_output_file)\n",
    "```\n",
    "Check `scripts/cspell_results.ipynb` for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cspell_example_train_root = os.path.join(train_dir, 'examples')\n",
    "if not os.path.exists(cspell_example_train_root):\n",
    "    os.makedirs(cspell_example_train_root)\n",
    "    \n",
    "example_stat = []\n",
    "for example in examples_train_cspell_all:\n",
    "    ex_id, note_id, typo_type, typo, left, right, correction = example\n",
    "    start = len(left)\n",
    "    end = start + len(typo)\n",
    "    output = left + typo + right\n",
    "    \n",
    "    example_fpath = os.path.join(cspell_example_train_root, f'{ex_id}.txt')\n",
    "    with open(example_fpath, 'w') as fd:\n",
    "        fd.write(output)\n",
    "    example_stat.append([ex_id, note_id, start, end, typo, correction])\n",
    "    print(f'{example_fpath} {note_id}[{start}:{end}] {typo} -> {correction}')\n",
    "    \n",
    "example_stat_fpath = os.path.join(cspell_example_train_root, 'example_stat.json')\n",
    "with open(example_stat_fpath, 'w') as fd:\n",
    "    json.dump(example_stat, fd)\n",
    "print(f'Write example stat to {example_stat_fpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cspell_example_test_root = os.path.join(test_dir, 'examples')\n",
    "if not os.path.exists(cspell_example_test_root):\n",
    "    os.makedirs(cspell_example_test_root)\n",
    "\n",
    "char_counter = collections.Counter()\n",
    "\n",
    "example_stat = []\n",
    "for example in examples_test_cspell_all:\n",
    "    ex_id, note_id, typo_type, typo, left, right, correction = example\n",
    "    start = len(left)\n",
    "    end = start + len(typo)\n",
    "    output = left + typo + right\n",
    "    \n",
    "    for c in output:\n",
    "        char_counter[c] += 1\n",
    "    \n",
    "    example_fpath = os.path.join(cspell_example_test_root, f'{ex_id}.txt')\n",
    "    with open(example_fpath, 'w') as fd:\n",
    "        fd.write(output)\n",
    "    example_stat.append([ex_id, note_id, start, end, typo, correction])\n",
    "    print(f'{example_fpath} {note_id}[{start}:{end}] {typo} -> {correction}')\n",
    "        \n",
    "example_stat_fpath = os.path.join(cspell_example_test_root, 'example_stat.json')\n",
    "with open(example_stat_fpath, 'w') as fd:\n",
    "    json.dump(example_stat, fd)\n",
    "print(f'Write example stat to {example_stat_fpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter examples by CSpell\n",
    "\n",
    "We further filter the examples that are not detected by CSpell software. Below are the masks that indicate whether each example's misspelling is detected by CSpell or not.\n",
    "\n",
    "To get the masks by parsing the CSpell output of the files written above, see `scripts/cspell_results.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cspell_train_mask = [\n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1\n",
    "]\n",
    "\n",
    "# After running CSpell and scripts/cspell_results.ipynb, you can get the same mask\n",
    "# cspell_train_mask = json.load(os.path.join(train_dir, 'cspell_train_mask.json'))\n",
    "\n",
    "print(f'Train examples detected by CSpell: {sum(cspell_train_mask)}/{len(cspell_train_mask)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cspell_test_mask = [\n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, \n",
    "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
    "]\n",
    "\n",
    "# After running CSpell and scripts/cspell_results.ipynb, you can get the same mask\n",
    "# cspell_test_mask = json.load(os.path.join(train_dir, 'cspell_test_mask.json'))\n",
    "\n",
    "print(f'Test examples detected by CSpell: {sum(cspell_test_mask)}/{len(cspell_test_mask)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filter examples with the CSpell masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_cspell_filtered = [\n",
    "    e for e, m in zip(dataset_train_all, cspell_train_mask) if m\n",
    "]\n",
    "print(f'Train set: {len(dataset_train_cspell_filtered)} examples')\n",
    "\n",
    "dataset_test_cspell_filtered = [\n",
    "    e for e, m in zip(dataset_test_all, cspell_test_mask) if m\n",
    "]\n",
    "print(f'Test set: {len(dataset_test_cspell_filtered)} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train_fpath = os.path.join(dataset_dir, output_train_fname)\n",
    "print(f'Write {len(dataset_train_cspell_filtered)} examples to {output_train_fpath}')\n",
    "write_dataset(dataset_train_cspell_filtered, output_train_fpath)\n",
    "\n",
    "output_test_fpath = os.path.join(dataset_dir, output_test_fname)\n",
    "print(f'Write {len(dataset_test_cspell_filtered)} examples to {output_test_fpath}')\n",
    "write_dataset(dataset_test_cspell_filtered, output_test_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
